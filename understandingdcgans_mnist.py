# -*- coding: utf-8 -*-
"""UnderstandingDCGANs-mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YP3izYxzbNxiuLsB5LuMRxhtrM3aaYfL
"""

#!pip3 install git+https://github.com/am1tyadav/tfutils.git

# import necessary packages
print('importing packages')
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Conv2DTranspose
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Reshape
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
import numpy as np
import os
import tfutils
import matplotlib.pyplot as plt
from PIL import Image

print("Tensorflow version:", tf.__version__)

# load dataset and normalize pixel values from 0-255 using tfutils
print('loading and processing dataset')
(x_train, y_train), (x_test, y_test) = tfutils.datasets.mnist.load_data(one_hot=False)

x_train = tfutils.datasets.mnist.load_subset([0], x_train, y_train)
x_test = tfutils.datasets.mnist.load_subset([0], x_test, y_test)

x = np.concatenate([x_train, x_test], axis=0)

# plotting 10 random examples from dataset
print('plotting examples')
tfutils.datasets.mnist.plot_ten_random_examples(plt, x, np.zeros((x.shape[0], 1))).show()

# build generator model
print('build generator model')
generatorModel = Sequential([
    Dense(256, activation='relu', input_shape=(28,)),
    Reshape((1, 1, 256)),

    Conv2DTranspose(256, 5, activation='relu'),
    BatchNormalization(),
    
    Conv2DTranspose(128, 5, activation='relu'),
    BatchNormalization(),

    Conv2DTranspose(64, 5, strides=2, activation='relu'),
    BatchNormalization(),

    Conv2DTranspose(32, 5, activation='relu'),
    BatchNormalization(),

    Conv2DTranspose(1, 4, activation='sigmoid')
  ])

generatorModel.summary()

# check for noisy image generated by generator model
noise_image = np.random.randn(1, 28)
generator_image = generatorModel.predict(noise_image)[0]

plt.figure()
plt.imshow(np.reshape(generator_image, (28, 28)), cmap='binary')

# build discriminator model - cnn model to classify images
print('build discriminator model')
discriminatorModel = Sequential([
  Conv2D(64, 3, strides=2, input_shape=(28, 28, 1)),
  LeakyReLU(),
  BatchNormalization(),

  Conv2D(128, 5, strides=2),
  LeakyReLU(),
  BatchNormalization(),

  Conv2D(256, 5, strides=2),
  LeakyReLU(),
  BatchNormalization(),

  Flatten(),
  Dense(1, activation='sigmoid')
])

optm = tf.keras.optimizers.Adam(lr=2e-4, beta_1=0.5)
discriminatorModel.compile(loss='binary_crossentropy', optimizer=optm, metrics=['accuracy'])
discriminatorModel.summary()

# building gan model
print('build GAN model')
input_layer = tf.keras.layers.Input(shape=(28,))
generator_output = generatorModel(input_layer)
discriminator_output = discriminatorModel(generator_output)

baseModel = Model(
    input_layer,
    discriminator_output
)

discriminatorModel.trainable = False
baseModel.compile(loss='binary_crossentropy', optimizer=optm, metrics=['accuracy'])
baseModel.summary()

# train gan model
print('train GAN model')
epochs = 25
batch_size = 128
steps_per_epoch = int(2 * x.shape[0]/batch_size)

plot = tfutils.plotting.DynamicPlot(plt, 5, 5, (8, 8))
print('generating images')
for epoch in range(epochs):
  
  plot.start_of_epoch(epoch)

  for step in range(steps_per_epoch):
    true_examples = x[int(batch_size/2)*step: int(batch_size/2)*(step + 1)]
    true_examples = np.reshape(true_examples, (true_examples.shape[0], 28, 28, 1))

    noise_image = np.random.randn(int(batch_size/2), 28)
    generated_examples = generatorModel.predict(noise_image)

    x_batch = np.concatenate([generated_examples, true_examples], axis=0)
    y_batch = np.array([0] * int(batch_size/2) + [1] * int(batch_size/2))

    indices = np.random.choice(range(batch_size), batch_size, replace=False)
    x_batch = x_batch[indices]
    y_batch = y_batch[indices]

    discriminatorModel.trainable = True
    discriminatorModel.train_on_batch(x_batch, y_batch)
    discriminatorModel.trainable = False

    loss, _ = baseModel.train_on_batch(noise_image, np.ones((int(batch_size/2), 1)))
    _, acc = discriminatorModel.evaluate(x_batch, y_batch, verbose=False)

  noise_image = np.random.randn(1, 28)
  generated_example = generatorModel.predict(noise_image)[0]

  plot.end_of_epoch(np.reshape(generated_example, (28, 28)), 'binary', 'DiscAcc:{:.2f}'.format(acc), 'GanLoss:{:.2f}'.format(loss))

